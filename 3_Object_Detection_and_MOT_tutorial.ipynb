{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Object_Detection_and_MOT_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlvlab/COSE474/blob/master/3_Object_Detection_and_MOT_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QX1esx9JMpFR"
      },
      "source": [
        "# **Multiple Object Tracking with PyTorch**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Reference**\n",
        "\n",
        "\n",
        "*   Object Detection with Faster R-CNN: https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch/ \n",
        "*   Simple Online and Realtime Tracking (SORT) algorithm for object ID tracking: https://arxiv.org/abs/1602.00763\n",
        "\n",
        "\n",
        "**Question**\n",
        "What is Multiple Object Tracking?\n",
        "- Object tracking is one of the tasks in computer vision, which is detecting an object and searching for that object in a video or a series of images (actually both meaning the same thing). \n",
        "- Surveillance cameras in public places for spotting suspicious activities or crimes, and a computer system called 'Hawk-eye' for tracking the trajectory of the ball in various sports are typical examples of applying object tracking in a real life.\n",
        "\n",
        "\n",
        "**Goals**\n",
        "\n",
        "\n",
        "1. We will use MOT17Det Dataset\n",
        "2. First part: Object Detection with **Faster R-CNN**\n",
        "3. Second part: Multiple Object(ID) Tracking with  **Simple Online and Realtime Tracking (SORT)** algorithm\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hzmQhgb43MMg"
      },
      "source": [
        "**0. Preparation**\n",
        "\n",
        "\n",
        "*   For your convenience, it is recommended to mount your Google Drive first.\n",
        "*   Then create extra space for this tutorial in there.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnS6Q7M7C2VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/drive/'\n",
        "drive.mount(root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8jnmft4v7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making Directory\n",
        "\n",
        "import os \n",
        "from os.path import join\n",
        "\n",
        "mot = \"My Drive/Colab Notebooks/MOT/\"   # a custom path. you can change if you want to\n",
        "MOT_PATH = join(root,mot)\n",
        "!mkdir \"{MOT_PATH}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zHl8FW6p1DI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**1. Dataset**\n",
        "\n",
        "\n",
        "*   https://motchallenge.net/ : MOT17Det Dataset for Pedestrian Detection Challenge\n",
        "*   We will only use MOT17-09 dataset for our task.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9lkwFuo2CK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download MOT17Det Dataset\n",
        "\n",
        "!wget -P \"{MOT_PATH}\" https://motchallenge.net/data/MOT17Det.zip\n",
        "!cd \"{MOT_PATH}\";unzip MOT17Det.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oHlCPGp6xZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove unwanted data for drive volume issue (optional)\n",
        "\n",
        "!cd \"{MOT_PATH}\";rm -rf test\n",
        "!cd \"{MOT_PATH}\";rm -rf train/MOT17-02;rm -rf train/MOT17-04;rm -rf train/MOT17-05\n",
        "!cd \"{MOT_PATH}\";rm -rf train/MOT17-10;rm -rf train/MOT17-11;rm -rf train/MOT17-13"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct_3R8Nf-GlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "motdata = join(MOT_PATH,'train/MOT17-09/img1/')\n",
        "sys.path.append(motdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_evT8k1S9GQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example: Original picture before detection\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import cv2\n",
        "\n",
        "list_motdata = os.listdir(motdata)  \n",
        "list_motdata.sort()\n",
        "\n",
        "img_ex_path = motdata + list_motdata[0]\n",
        "img_ex_origin = cv2.imread(img_ex_path)\n",
        "img_ex = cv2.cvtColor(img_ex_origin, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img_ex)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvuU_xZjqrJd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**2. Object Detection with Faster R-CNN**\n",
        "\n",
        "*  We will use a pretrained Faster R-CNN model using ResNet50 as a backbone with FPN.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IEdaeDV6xfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required packages/modules first\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaFru4rA6xrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the pretrained Faster R-CNN model from torchvision\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBcUWr2W9Tfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the class names given by PyTorch's official Docs\n",
        "\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAbS5uwE9vd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a function for get a prediction result from the model\n",
        "\n",
        "def get_prediction(img_path, threshold):\n",
        "  img = Image.open(img_path) # Load the image\n",
        "  transform = T.Compose([T.ToTensor()]) # Defing PyTorch Transform\n",
        "  img = transform(img) # Apply the transform to the image\n",
        "  pred = model([img]) # Pass the image to the model\n",
        "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())] # Get the Prediction Score\n",
        "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())] # Bounding boxes\n",
        "  pred_score = list(pred[0]['scores'].detach().numpy())\n",
        "  pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1] # Get list of index with score greater than threshold.\n",
        "  pred_boxes = pred_boxes[:pred_t+1]\n",
        "  pred_class = pred_class[:pred_t+1]\n",
        "  return pred_boxes, pred_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa4XIuLH6xoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a api function for object detection\n",
        "\n",
        "def object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=1.5, text_th=3):\n",
        " \n",
        "  boxes, pred_cls = get_prediction(img_path, threshold) # Get predictions\n",
        "  img = cv2.imread(img_path) # Read image with cv2\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "  for i in range(len(boxes)):\n",
        "    cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th) # Draw Rectangle with the coordinates\n",
        "    cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
        "  plt.figure(figsize=(15,20)) # display the output image\n",
        "  plt.imshow(img)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDlyeXSXHMLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example: After detection\n",
        "object_detection_api(img_ex_path,threshold=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8gXp0eInzV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   The picture above is an example of applying Detection Network (in our case, Faster R-CNN).\n",
        "*   Since the purpose of dataset we are using is 'tracking', you can see that most of the detected classes are 'person'.\n",
        "*   We need a prediction result (bbs offset, class label, pred scores) for all the images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCelLE4jq8ye",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**3. Object ID Tracking with SORT**\n",
        "\n",
        "\n",
        "*   Simple Online and Realtime Tracking (SORT) algorithm for object ID tracking \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1WuiRXsHMPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Git clone: SORT Algorithm\n",
        "\n",
        "!cd \"{MOT_PATH}\";git clone https://github.com/abewley/sort.git\n",
        "  \n",
        "sort = join(MOT_PATH,'sort/')\n",
        "sys.path.append(sort)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byjLd9LkKTux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# requirement for sort\n",
        "!cd \"{sort}\";pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk2pt2SyuH9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optional: if error occurs, you might need to re-install scikit-image and imgaug\n",
        "\n",
        "!pip uninstall scikit-image\n",
        "!pip uninstall imgaug\n",
        "!pip install imgaug\n",
        "!pip install -U scikit-image\n",
        "\n",
        "import skimage\n",
        "print(skimage.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nfV0kTkMmsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detection information on all the images is well-refined as a json file, which is available at our course git repo\n",
        "\n",
        "!cd \"{MOT_PATH}\";git clone https://github.com/mlvlab/COSE474.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdErbmxk96w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import collections\n",
        "from pprint import pprint\n",
        "from sort import *\n",
        "\n",
        "jsonpath = join(MOT_PATH,'COSE474/3_MOT_detinfo.json')\n",
        "\n",
        "with open(jsonpath) as data_file:    \n",
        "   data = json.load(data_file)\n",
        "odata = collections.OrderedDict(sorted(data.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eONi2h58yKjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's check out downloaded json file\n",
        "\n",
        "pprint(odata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnsyoUpmz42L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   For each image, bbs offset, class label, pred scores are all annotated.\n",
        "*   Labels are annotated as a number - not a word, and for further information, go to the website below.\n",
        "* https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUB25un4yJsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = motdata    # img root path\n",
        "\n",
        "# Making new directory for saving results\n",
        "save_path = join(MOT_PATH,'save/')\n",
        "!mkdir \"{save_path}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9vAOQQ960r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mot_tracker = Sort()      # Tracker using SORT Algorithm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvfa1Ls964o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key in odata.keys():   \n",
        "    arrlist = []\n",
        "    det_img = cv2.imread(os.path.join(img_path, key))\n",
        "    overlay = det_img.copy()\n",
        "    det_result = data[key] \n",
        "    \n",
        "    for info in det_result:\n",
        "        bbox = info['bbox']\n",
        "        labels = info['labels']\n",
        "        scores = info['scores']\n",
        "        templist = bbox+[scores]\n",
        "        \n",
        "        if labels == 1: # label 1 is a person in MS COCO Dataset\n",
        "            arrlist.append(templist)\n",
        "            \n",
        "    track_bbs_ids = mot_tracker.update(np.array(arrlist))\n",
        "    \n",
        "    mot_imgid = key.replace('.jpg','')\n",
        "    newname = save_path + mot_imgid + '_mot.jpg'\n",
        "    print(mot_imgid)\n",
        "    \n",
        "    for j in range(track_bbs_ids.shape[0]):  \n",
        "        ele = track_bbs_ids[j, :]\n",
        "        x = int(ele[0])\n",
        "        y = int(ele[1])\n",
        "        x2 = int(ele[2])\n",
        "        y2 = int(ele[3])\n",
        "        track_label = str(int(ele[4])) \n",
        "        cv2.rectangle(det_img, (x, y), (x2, y2), (0, 255, 255), 4)\n",
        "        cv2.putText(det_img, '#'+track_label, (x+5, y-10), 0,0.6,(0,255,255),thickness=2)\n",
        "        \n",
        "    cv2.imwrite(newname,det_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kyVRJJLMnNGo"
      },
      "source": [
        "\n",
        "---\n",
        "It's all done!\n",
        "\n",
        "\n",
        "*   Finally, you can get a sequence of image with each Tracking ID for every detected person. \n",
        "*   Check '3_MOT_result.gif' for whole demo experience.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    }
  ]
}
